---
translationKey: ''
title: NVIDIA delivers the world’s smallest AI supercomputer to Elon Musk.
date: 2025-10-16T19:28:00.000+09:00
lang: en
tags:
  - NVIDIA AI SpaceX
summary: NVIDIA CEO Jensen Huang personally delivered the company’s newly launched DGX Spark AI supercomputer to Elon Musk on October 13 at SpaceX’s Starbase. This event marks a symbolic moment—the world’s most powerful rocket meets the world’s smallest supercomputer.
draft: false
---
NVIDIA CEO Jensen Huang personally delivered the company’s newly launched DGX Spark AI supercomputer to Elon Musk on October 13 at SpaceX’s Starbase. This event marks a symbolic moment—the world’s most powerful rocket meets the world’s smallest supercomputer.

The delivery took place as SpaceX prepared for the Starship 11 test flight, with Huang joking, “Delivering the smallest supercomputer next to the biggest rocket.” The timing was not coincidental; the handover occurred just hours before the 403-foot Starship roared into the Texas night sky for its eleventh test flight.

This event is historically significant for the AI industry. In 2016, when Musk was involved in a startup, Huang delivered the first DGX-1 supercomputer to OpenAI. That original system helped train models that eventually led to the creation of ChatGPT. Now, nine years later, Huang delivers a device that integrates similar computing power into a 1.2-kilogram desktop form factor.

![](/images/posts/L1031167-retouch.jpg)

“The DGX-1 we built in 2016 enabled AI researchers to have their own supercomputer. I personally delivered the first system to Elon at a tiny startup called OpenAI, which gave birth to ChatGPT and started an AI revolution,” Huang said in NVIDIA’s announcement. Musk himself noted on social media that the new DGX Spark “offers about 100 times the performance per watt compared to the DGX-1.”

DGX Spark represents NVIDIA’s effort to democratize high-performance AI computing beyond data centers. Powered by the company’s GB10 Grace Blackwell superchip, it delivers up to 1 petaflop of AI performance and comes with 128GB of unified CPU and GPU memory. It can locally run AI models with up to 200 billion parameters and fine-tune models up to 70 billion parameters.

Early adopters include major tech companies such as Google, Meta, and Microsoft, as well as research institutions like NYU’s Global Frontiers Laboratory. The device is available today via NVIDIA’s official website and partner manufacturers including Dell, HP, and Lenovo, priced at $3,999.

However, some industry observers are skeptical about the scale of the launch. According to SemiAccurate, initial distribution across all manufacturers may be less than double digits, prompting some to call it more of a PR stunt than mass production.

The delivery took place as SpaceX prepared for the Starship 11 test flight, with Huang joking, “Delivering the smallest supercomputer next to the biggest rocket.” The timing was not coincidental; the handover occurred just hours before the 403-foot Starship roared into the Texas night sky for its eleventh test flight.

This event is historically significant for the AI industry. In 2016, when Musk was involved in a startup, Huang delivered the first DGX-1 supercomputer to OpenAI. That original system helped train models that eventually led to the creation of ChatGPT. Now, nine years later, Huang delivers a device that integrates similar computing power into a 1.2-kilogram desktop form factor.

“The DGX-1 we built in 2016 enabled AI researchers to have their own supercomputer. I personally delivered the first system to Elon at a tiny startup called OpenAI, which gave birth to ChatGPT and started an AI revolution,” Huang said in NVIDIA’s announcement. Musk himself noted on social media that the new DGX Spark “offers about 100 times the performance per watt compared to the DGX-1.”

DGX Spark represents NVIDIA’s effort to democratize high-performance AI computing beyond data centers. Powered by the company’s GB10 Grace Blackwell superchip, it delivers up to 1 petaflop of AI performance and comes with 128GB of unified CPU and GPU memory. It can locally run AI models with up to 200 billion parameters and fine-tune models up to 70 billion parameters.

Early adopters include major tech companies such as Google, Meta, and Microsoft, as well as research institutions like NYU’s Global Frontiers Laboratory. The device is available today via NVIDIA’s official website and partner manufacturers including Dell, HP, and Lenovo, priced at $3,999.

However, some industry observers are skeptical about the scale of the launch. According to SemiAccurate, initial distribution across all manufacturers may be less than double digits, prompting some to call it more of a PR stunt than mass production.
