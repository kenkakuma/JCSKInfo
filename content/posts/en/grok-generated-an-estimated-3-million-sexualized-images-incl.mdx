---
title: "Grok generated an estimated 3 million sexualized images\_— including 23,000 of children —\_over 11 days"
date: '2026-01-22T17:50:53.000Z'
lang: en
translationKey: grok-generated-an-estimated-3-million-sexualized-images-incl
tags:
  - Celebrities
  - site|engadget
  - provider_name|Engadget
  - region|US
  - language|en-US
summary: >-
  We already knew xAI's Grok was barraging X with [nonconsensual sexual images
  of real
  people](https://www.engadget.com/ai/elon-musks-grok-ai-posted-csam-image-fo...
draft: true
image: >-
  https://d29szjachogqwa.cloudfront.net/images/2026-01/440c8f59-6000-4b81-a2d8-c404e6f5545f
sourceUrl: >-
  https://www.engadget.com/ai/grok-generated-an-estimated-3-million-sexualized-images--including-23000-of-children--over-11-days-175053250.html?src=rss
sourceName: Engadget
collectedAt: '2026-01-22T18:22:19.803Z'
---
We already knew xAI's Grok was barraging X with [nonconsensual sexual images of real people](https://www.engadget.com/ai/elon-musks-grok-ai-posted-csam-image-following-safeguard-lapses-140521454.html). But now there are some numbers to put things in perspective. Over an 11-day period, Grok generated an estimated 3 million sexualized images — including an estimated 23,000 of children.

Put another way, Grok generated an estimated 190 sexualized images per minute during that 11-day period. Among those, it made a sexualized image of children once every 41 seconds.

On Thursday, the Center for Countering Digital Hate (CCDH) [published its findings](https://counterhate.com/research/grok-floods-x-with-sexualized-images/). The British nonprofit based its findings on a random sample of 20,000 Grok images from December 29 to January 9. The CCDH then extrapolated a broader estimate based on the 4.6 million images Grok generated during that period.

The research defined sexualized images as those with "photorealistic depictions of a person in sexual positions, angles, or situations; a person in underwear, swimwear or similarly revealing clothing; or imagery depicting sexual fluids." The CCDH didn't take image prompts into account, so the estimate doesn't differentiate between nonconsensual sexualized versions of real photos and those generated exclusively from a text prompt.

The CCDH used an AI tool to identify the proportion of the sampled images that were sexualized. That may warrant some degree of caution in the findings. However, I'm told that many third-party analytics services for X have reliable data because they use the platform's API.

On January 9, xAI restricted Grok's ability to edit existing images to paid users. (That didn't solve the problem; it merely turned it into a premium feature.) Five days later, X [restricted Grok's ability to digitally undress real people](https://www.engadget.com/ai/x-says-grok-will-no-longer-edit-images-of-real-people-into-bikinis-231430257.html).

![WASHINGTON, DC - JUNE 23: Google CEO Sundar Pichai (L) and Apple CEO Tim Cook (R) listen as U.S. President Joe Biden speaks during a roundtable with American and Indian business leaders in the East Room of the White House on June 23, 2023 in Washington, DC. Biden and Indian Prime Minister Narendra Modi held the meeting to meet with a range of leaders from the tech and business worlds and to discuss topics including innovation and AI. (Photo by Anna Moneymaker/Getty Images)](https://d29szjachogqwa.cloudfront.net/images/2026-01/440c8f59-6000-4b81-a2d8-c404e6f5545f)

WASHINGTON, DC - JUNE 23: Google CEO Sundar Pichai (L) and Apple CEO Tim Cook (R) listen as U.S. President Joe Biden speaks during a roundtable with American and Indian business leaders in the East Room of the White House on June 23, 2023 in Washington, DC. Biden and Indian Prime Minister Narendra Modi held the meeting to meet with a range of leaders from the tech and business worlds and to discuss topics including innovation and AI. (Photo by Anna Moneymaker/Getty Images)

Anna Moneymaker via Getty Images

But that restriction only applied to X; the standalone Grok app [reportedly](https://www.washingtonpost.com/technology/2026/01/15/grok-ai-image-generator-sexualized/) continues to generate these images. Since Apple and Google host the apps — which their policies explicitly prohibit — you might expect them to remove them from their stores. Well, in that case, you'd be wrong.

So far, Tim Cook's Apple and Sundar Pichai's Google haven’t removed Grok from their stores — unlike similar “nudifying” apps from other developers. The companies also didn’t take any action on X while it was producing the images. That’s despite 28 women’s groups (and other progressive advocacy nonprofits) [publishing an open letter calling on the companies to act](https://www.engadget.com/big-tech/28-advocacy-groups-call-on-apple-and-google-to-ban-grok-x-over-nonconsensual-deepfakes-215048460.html).

The companies haven't replied to multiple requests for comment from Engadget. To my knowledge, they haven't acknowledged the issue publicly in any format, nor have they responded to questions from other media outlets.

![Grok - App Store and Play Store listings](https://d29szjachogqwa.cloudfront.net/images/user-uploaded/grok_stores.jpg)

Grok - App Store and Play Store listings

Apple / Google

The research’s findings on sexualized images included numerous outputs of people wearing transparent bikinis or micro-bikinis. The CCDH referred to one of a "uniformed healthcare worker with white fluids visible between her spread legs." Others included women wearing only dental floss, Saran Wrap or transparent tape. One depicted Ebba Busch, Sweden's Deputy Prime Minister, "wearing a bikini with white fluid on her head."

Other public figures were part of that group. They include Selena Gomez, Taylor Swift, Billie Eilish, Ariana Grande, Ice Spice, Nicki Minaj, Christina Hendricks, Millie Bobby Brown and Kamala Harris.

Examples of children include someone using Grok to edit a child's "before-school selfie" into an image of her in a bikini. Another image depicted "six young girls wearing micro bikinis." The CCDH said that, as of January 15, both of these posts were still live on X.

In total, 29 percent of the sexualized images of children identified in the sample were still accessible on X as of January 15. The research found that even after posts were removed, the images remained accessible via their direct URLs.

You can [read the CCDH's report](https://counterhate.com/research/grok-floods-x-with-sexualized-images/) for more details on the results and methodology. We’ll update this story if we receive a reply from Apple or Google.

This article originally appeared on Engadget at https://www.engadget.com/ai/grok-generated-an-estimated-3-million-sexualized-images--including-23000-of-children--over-11-days-175053250.html?src=rss
