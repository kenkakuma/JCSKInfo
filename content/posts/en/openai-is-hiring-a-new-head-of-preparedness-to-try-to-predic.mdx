---
title: >-
  OpenAI is hiring a new Head of Preparedness to try to predict and mitigate
  AI's harms
date: '2025-12-27T22:03:30.000Z'
lang: en
translationKey: openai-is-hiring-a-new-head-of-preparedness-to-try-to-predic
tags:
  - Arts & Entertainment
  - site|engadget
  - provider_name|Engadget
  - region|US
  - language|en-US
summary: >-
  OpenAI is looking for a new Head of Preparedness who can help it anticipate
  the potential harms of its models and how they can be abused, in order to
  guide the...
draft: true
sourceUrl: >-
  https://www.engadget.com/ai/openai-is-hiring-a-new-head-of-preparedness-to-try-to-predict-and-mitigate-ais-harms-220330486.html?src=rss
sourceName: Engadget
collectedAt: '2025-12-28T01:18:19.475Z'
---
OpenAI is looking for a new Head of Preparedness who can help it anticipate the potential harms of its models and how they can be abused, in order to guide the company's safety strategy. It comes at the end of a year that's seen OpenAI hit with numerous accusations about ChatGPT's impacts on users' mental health, including a few [wrongful death](https://www.engadget.com/ai/lawsuit-accuses-chatgpt-of-reinforcing-delusions-that-led-to-a-womans-death-183141193.html) [lawsuits](https://www.engadget.com/ai/the-first-known-ai-wrongful-death-lawsuit-accuses-openai-of-enabling-a-teens-suicide-212058548.html). In a post on X about the position, OpenAI CEO [Sam Altman](https://x.com/sama/status/2004939524216910323?s=20) acknowledged that the "potential impact of models on mental health was something we saw a preview of in 2025," along with other "real challenges" that have arisen alongside models' capabilities. The Head of Preparedness "is a critical role at an important time," he said.

Per the [job listing](https://openai.com/careers/head-of-preparedness-san-francisco/), the Head of Preparedness (who will make $555K, plus equity), "will lead the technical strategy and execution of OpenAI’s [Preparedness framework](https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf), our framework explaining OpenAI’s approach to tracking and preparing for frontier capabilities that create new risks of severe harm." It is, according to Altman, "a stressful job and you'll jump into the deep end pretty much immediately."

Over the last couple of years, [OpenAI's safety teams](https://www.engadget.com/the-openai-team-tasked-with-protecting-humanity-is-no-more-183433377.html) have [undergone](https://shopping.yahoo.com/rdlw?merchantId=34e37b9c-8975-48da-aa39-df8bcd5badc3&siteId=us-engadget&pageId=1p-autolink&contentUuid=0f08d742-f952-4b3f-a1b5-13ad710de592&featureId=text-link&merchantName=CNBC&linkText=undergone&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5jbmJjLmNvbS8yMDI0LzEwLzI0L29wZW5haS1taWxlcy1icnVuZGFnZS1hZ2ktcmVhZGluZXNzLmh0bWwiLCJjb250ZW50VXVpZCI6IjBmMDhkNzQyLWY5NTItNGIzZi1hMWI1LTEzYWQ3MTBkZTU5MiIsIm9yaWdpbmFsVXJsIjoiaHR0cHM6Ly93d3cuY25iYy5jb20vMjAyNC8xMC8yNC9vcGVuYWktbWlsZXMtYnJ1bmRhZ2UtYWdpLXJlYWRpbmVzcy5odG1sIn0&signature=AQAAAbQYCN0bjzdWlI-Nzy-tYItwHhtf_gG8HFqtVVSR9n2E&gcReferrer=https%3A%2F%2Fwww.cnbc.com%2F2024%2F10%2F24%2Fopenai-miles-brundage-agi-readiness.html) a lot of [changes](https://www.engadget.com/openais-new-safety-team-is-led-by-board-members-including-ceo-sam-altman-164927745.html). The company's [former Head of Preparedness](https://shopping.yahoo.com/rdlw?merchantId=34e37b9c-8975-48da-aa39-df8bcd5badc3&siteId=us-engadget&pageId=1p-autolink&contentUuid=0f08d742-f952-4b3f-a1b5-13ad710de592&featureId=text-link&merchantName=CNBC&linkText=former+Head+of+Preparedness&custData=eyJzb3VyY2VOYW1lIjoiV2ViLURlc2t0b3AtVmVyaXpvbiIsImxhbmRpbmdVcmwiOiJodHRwczovL3d3dy5jbmJjLmNvbS8yMDI0LzA3LzIzL29wZW5haS1yZW1vdmVzLWFpLXNhZmV0eS1leGVjdXRpdmUtYWxla3NhbmRlci1tYWRyeS1mcm9tLXJvbGUuaHRtbCIsImNvbnRlbnRVdWlkIjoiMGYwOGQ3NDItZjk1Mi00YjNmLWExYjUtMTNhZDcxMGRlNTkyIiwib3JpZ2luYWxVcmwiOiJodHRwczovL3d3dy5jbmJjLmNvbS8yMDI0LzA3LzIzL29wZW5haS1yZW1vdmVzLWFpLXNhZmV0eS1leGVjdXRpdmUtYWxla3NhbmRlci1tYWRyeS1mcm9tLXJvbGUuaHRtbCJ9&signature=AQAAAdsz6AvfuE7dz8c_i_YSdG04VQV6oVNXurAIRmGLFRnx&gcReferrer=https%3A%2F%2Fwww.cnbc.com%2F2024%2F07%2F23%2Fopenai-removes-ai-safety-executive-aleksander-madry-from-role.html), Aleksander Madry, [was reassigned](https://www.reuters.com/technology/artificial-intelligence/openai-reassigns-ai-safety-leader-madry-information-reports-2024-07-23/) back in July 2024, and Altman said at the time that the role would be taken over by execs Joaquin Quinonero Candela and Lilian Weng. Weng [left the company](https://techcrunch.com/2024/11/08/openai-loses-another-lead-safety-researcher-lilian-weng/) a few months later, and in July 2025, Quinonero Candela [announced](https://x.com/jquinonero/status/1934716214473048438?s=20) his move away from the preparedness team to lead recruiting at OpenAI. 

This article originally appeared on Engadget at https://www.engadget.com/ai/openai-is-hiring-a-new-head-of-preparedness-to-try-to-predict-and-mitigate-ais-harms-220330486.html?src=rss
